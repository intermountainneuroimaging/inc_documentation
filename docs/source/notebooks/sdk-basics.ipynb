{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flyhweel Software Developer Kit (SDK) Basics and Helpful Hints\n",
    "\n",
    "**Date modified:** 28-July-2022 <br>\n",
    "**Authors:** Amy Hegarty, Lena Sherbakov, Intermountain Neuroimaging Consortium\n",
    "\n",
    "**Description:** <br>\n",
    "The following includes a set of basic SDK commands for Flywheel. Examples included below:\n",
    "1. Basic Flywheel Heirarchy (finding a session)\n",
    "2. Pulling Data To Scatch workspace\n",
    "3. Uploading Analyses to Flywheel\n",
    "\n",
    "**Links** <br>\n",
    "SDK <https://flywheel-io.gitlab.io/product/backend/sdk/branches/master/python/index.html>\n",
    "\n",
    "Flywheel Examples <https://gitlab.com/flywheel-io/public/flywheel-tutorials/-/blob/master/python/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys, subprocess, os, nipype, datetime, logging\n",
    "sys.path.append('/projects/ics/software/flywheel-python/bids-client/')\n",
    "sys.path.append('/projects/ics/software/flywheel-python/')\n",
    "from getpass import getpass\n",
    "import flywheel, flywheel_gear_toolkit\n",
    "from flywheel_gear_toolkit.interfaces.command_line import (\n",
    "    build_command_list,\n",
    "    exec_command,\n",
    ")\n",
    "from flywheel_gear_toolkit.utils.zip_tools import unzip_archive, zip_output\n",
    "from utils.zip_htmls import zip_htmls\n",
    "from flywheel_bids.export_bids import export_bids\n",
    "from flywheel_bids.export_bids import download_bids_dir\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting functions\n",
    "def analysis_exists(session, analysis_name, exclude_list=[]):\n",
    "    # Returns True if analysis already exists with a running or complete status, else false\n",
    "    # make sure to pass full session object (use fw.get_session(session.id))\n",
    "    #\n",
    "    #Get all analyses for the session\n",
    "    flag=False\n",
    "    for analysis in session.analyses:\n",
    "        #only print ones that match the  analysis label\n",
    "        if analysis_name in analysis.label:\n",
    "            #filter for only successful job\n",
    "            analysis_job=analysis.job\n",
    "            if any(analysis_job.state in string for string in [\"complete\",\"running\",\"pending\"]):\n",
    "                if analysis_job.failure_reason is None:\n",
    "                    flag=True\n",
    "        #check if session is in exclude list\n",
    "        if any(session.id in string for string in exclude_list):\n",
    "            flag=True\n",
    "    \n",
    "    return flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flywheel API Key and Client\n",
    "An API Key is required to interact with the datasets on flywheel db. More on this in the Flywheel SDK doc [here](https://flywheel-io.gitlab.io/product/backend/sdk/branches/master/python/getting_started.html#api-key). Here we pull the API key directly from the user's os enviornment, set within the flywheel command line interface.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "log = logging.getLogger('root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client, using CLI credentials\n",
    "fw = flywheel.Client()\n",
    "\n",
    "# who am I logged in as?\n",
    "log.info('You are now logged in as %s to %s', fw.get_current_user()['email'], fw.get_config()['site']['api_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing a Flywheel Project\n",
    "The `fw.lookup` function can be used to find any container in flywheel by path. This is an easy way to find projects, subjects, or sessions. Lets view a Flywheel project and list all sessions and their scan date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = fw.lookup('<group>/<project>')\n",
    "project.reload()\n",
    "for session in project.sessions.find():\n",
    "    # Loop through all sessions in the subject container. \n",
    "    dt = session.timestamp\n",
    "    if not dt:\n",
    "        dt = \"NAN\"\n",
    "    else:\n",
    "        dt = dt.strftime(\" %x %X\")\n",
    "    print('%s: Subject: %s Session: %s\\tScanning Date: %s' % (session.id, session.subject.label, session.label, dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing a Flywheel Analysis \n",
    "Similarly, we can view analyses that have been either uploaded to Flywheel or generated by running flywheel gears. Here, lets look for all analyses attached to a single session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by finding a session of interest\n",
    "session = fw.lookup('<group>/<project>/<subject>/<session>')\n",
    "\n",
    "# we need to take an extra step to get the full session object, not just basic info \n",
    "session_object = fw.get_session(session.id)\n",
    "\n",
    "# print all the analyses for this session\n",
    "for analysis in session_object.analyses:\n",
    "    if hasattr(analysis.job,'state'):\n",
    "        print('%s: %s %s' % (analysis.id, analysis.label, analysis.job.state))\n",
    "    else:\n",
    "        print('%s: %s' % (analysis.id, analysis.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data From Flywheel to Local Scratch (Part 1, Analyses)\n",
    "Often times you need to use data in flywheel as inputs for group level analyses. At present this is still most easily accomplished by exporting the data from file to a scatch filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to scratch directory\n",
    "username=os.getenv('USER')\n",
    "scratch='/scratch/summit/'+username'/''\n",
    "os.chdir(scratch)\n",
    "\n",
    "# find the analysis you wish to download\n",
    "analysis_id='629f8f5cbffdbee5eb7dcb37'\n",
    "analysis=fw.get(id=analysis_id)\n",
    "\n",
    "# Download the data to scratch\n",
    "for fl in analysis.files:\n",
    "    fl.download(scratch+fl['name'])\n",
    "\n",
    "    # unzip files\n",
    "    if '.zip' in fl['name']:\n",
    "        zipfile = ZipFile(scratch+fl['name'], \"r\")\n",
    "        zipfile.extractall(scratch)\n",
    "\n",
    "# Run your computations! Here lets just list the contents of the directory and store that in a text file\n",
    "os.system('mkdir -p output ; ls -l '+scratch+' > output/out.log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Results to Flywheel Analysis (Part 1, Session Analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you have finished your analysis, we need to upload your files and store some critical metadata in flywheel\n",
    "\n",
    "# session add analysis, zip outputs, upload\n",
    "# ...#zip output except for scratch\n",
    "log.info('Zipping contents of directory %s', scratch+'output')\n",
    "zip_output(scratch,'output', \"output.zip\", exclude_files=['scratch'])\n",
    "\n",
    "#create an analysis for that session\n",
    "timestamp=os.path.getmtime(scratch+'output')\n",
    "dtobject = datetime.fromtimestamp(timestamp)\n",
    "analysis = session_object.add_analysis(label='Sample Upload '+dtobject.strftime(\" %x %X\"))\n",
    "\n",
    "#upload analysis files\n",
    "analysis.upload_output(scratch+'output.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Results to Flywheel Analysis (Part 2, Project Analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing for project\n",
    "\n",
    "#create an analysis for that project\n",
    "timestamp=os.path.getmtime(scratch+'output')\n",
    "dtobject = datetime.fromtimestamp(timestamp)\n",
    "analysis = project.add_analysis(label='Sample Upload '+dtobject.strftime(\" %x %X\"))\n",
    "\n",
    "#upload analysis files\n",
    "analysis.upload_output(scratch+'output.zip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Examples Looping Through All Sessions\n",
    "Here is some example code where we loop through all sessions to check if an analysis exists. We will use a function we defined at the top of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session in project.sessions.find():\n",
    "    full_session = fw.get_session(session.id)\n",
    "    flag = analysis_exists(full_session, \"hcp\")\n",
    "    print('%s: %s %s' % (session.subject.label, session.label, flag))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_zip_analysis(session_object,root_dir,source_dir):\n",
    "    subject=session_object.subject.label\n",
    "    session = session_object.label\n",
    "    \n",
    "    if not os.path.exists(root_dir+'/'+\"pipeline_outputs.zip\") and os.path.exists(root_dir+'/'+source_dir+'/'+subject+'/'+session):\n",
    "        run_upload=True\n",
    "\n",
    "    if run_upload:\n",
    "        #zip output except for scratch\n",
    "        log.info('Zipping contents of directory %s', root_dir+'/'+source_dir+'/'+subject+'/'+session)\n",
    "        zip_output(root_dir,source_dir+'/'+subject+'/'+session,\"fw_uploads/pipeline_outputs.zip\",exclude_files=['scratch'])\n",
    "        \n",
    "        #zip logs\n",
    "        log.info('Zipping logs %s', root_dir+'/'+source_dir+'/'+subject+'/'+session)\n",
    "        zip_output(root_dir,source_dir+'/logs/'+subject,\"fw_uploads/pipeline_logs.zip\",exclude_files=['scratch'])\n",
    "        \n",
    "        #zip scripts (same for all sessions)\n",
    "        if not os.path.exists(root_dir+'/fw_uploads/run_scripts.zip'):\n",
    "            zip_output(root_dir,\"scripts/flywheel_scripts\",\"fw_uploads/run_scripts.zip\",exclude_files=['scratch'])\n",
    "            \n",
    "        #create an analysis for that session\n",
    "        timestamp=os.path.getmtime(root_dir+'/'+source_dir+'/'+subject+'/'+session)\n",
    "        dtobject = datetime.fromtimestamp(timestamp)\n",
    "        analysis = session_object.add_analysis(label='banich_fmripreproc'+dtobject.strftime(\" %x %X\"))\n",
    "        log.info('Creating analysis %s', 'banich_fmripreproc'+dtobject.strftime(\" %x %X\"))\n",
    "\n",
    "        #loop through all files to upload\n",
    "        for filename in sorted(os.listdir(root_dir+'/fw_uploads/')):\n",
    "            file_out=os.path.join(root_dir,\"fw_uploads\",filename)\n",
    "\n",
    "            # checking if it is a file\n",
    "            if os.path.isfile(file_out):\n",
    "                log.info('Uploading %s', file_out)\n",
    "                #upload output file to analysis container\n",
    "                analysis.upload_output(file_out)\n",
    "            \n",
    "    else:\n",
    "        if os.path.exists(root_dir+'/'+output_zip_file):\n",
    "            log.info('Output zipped file already exists')\n",
    "        if not os.path.exists(root_dir+'/'+source_dir+'/sub-'+subject+'/ses-'+session):\n",
    "            log.info('Directory path selected for output zip does not exist')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "           \n",
    "# Zip and Upload 1st level feat!        \n",
    "def upload_feat_analysis(session_object,root_dir,source_dir):\n",
    "    # for this analysis - make sure the source path has the correct task name included (e.g. feat/sub-001/task1.feat)\n",
    "    subject=session_object.subject.label\n",
    "    session = session_object.label\n",
    "    taskrun = source_dir.split('.')[0].split('/')[-1]\n",
    "    \n",
    "    if not os.path.exists(root_dir+'/fw_feat_uploads/'+\"feat.zip\") and os.path.exists(root_dir+'/'+source_dir):\n",
    "        run_upload=True\n",
    "\n",
    "    if run_upload:\n",
    "        #zip output except for scratch\n",
    "        log.info('Zipping contents of directory %s', root_dir+'/'+source_dir)\n",
    "        zip_output(root_dir,source_dir,\"fw_feat_uploads/feat.zip\",exclude_files=['scratch'])\n",
    "        \n",
    "        #zip logs\n",
    "        log.info('Zipping logs %s', root_dir+'/'+source_dir+'/logs')\n",
    "        zip_output(root_dir,source_dir+'/logs',\"fw_feat_uploads/feat_logs.zip\",exclude_files=['scratch'])\n",
    "        \n",
    "        # zip htmls -- note you need to confirm htmls outside of flywheel first!\n",
    "        zip_htmls(root_dir+'/fw_feat_uploads/', '', source_dir+'/htmls/' )\n",
    "        \n",
    "        # analysis_configuration (design.fsf)\n",
    "        os.system('cp '+root_dir+'/'+source_dir+'/design.fsf '+root_dir+'fw_feat_uploads/design.fsf')\n",
    "        \n",
    "        #create an analysis for that session\n",
    "        timestamp=os.path.getmtime(root_dir+'/'+source_dir)\n",
    "        dtobject = datetime.fromtimestamp(timestamp)\n",
    "        analysis = session_object.add_analysis(label='feat 1st-level:'+taskrun+dtobject.strftime(\" %x %X\"))\n",
    "        log.info('Creating analysis %s', 'feat 1st-level:'+taskrun+dtobject.strftime(\" %x %X\"))\n",
    "\n",
    "        #loop through all files to upload\n",
    "        for filename in sorted(os.listdir(root_dir+'/fw_feat_uploads/')):\n",
    "            file_out=os.path.join(root_dir,\"fw_feat_uploads\",filename)\n",
    "\n",
    "            # checking if it is a file\n",
    "            if os.path.isfile(file_out):\n",
    "                log.info('Uploading %s', file_out)\n",
    "                #upload output file to analysis container\n",
    "                analysis.upload_output(file_out)\n",
    "            \n",
    "    else:\n",
    "        if os.path.exists(root_dir+'/'+output_zip_file):\n",
    "            log.info('Output zipped file already exists')\n",
    "        if not os.path.exists(root_dir+'/'+source_dir+'/sub-'+subject+'/ses-'+session):\n",
    "            log.info('Directory path selected for output zip does not exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### *Thats all Folks!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
